{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brX4ZlQoc9ss"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: output: File exists\n",
      "/Users/lennartkerkvliet/Student/ICCV2019-LearningToPaint/baseline_modelfree/Renderer/bezierpath.py:21: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self.z0 = (int)(1 + z0 * width // 2)\n",
      "/Users/lennartkerkvliet/Student/ICCV2019-LearningToPaint/baseline_modelfree/Renderer/bezierpath.py:22: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self.z2 = (int)(1 + z2 * width // 2)\n",
      "/Users/lennartkerkvliet/Student/ICCV2019-LearningToPaint/baseline_modelfree/test.py:48: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  stroke = 1 - torch.tensor(paths)\n",
      "canvas step 0, L2Loss = 0.02513175643980503\n",
      "canvas step 1, L2Loss = 0.016571354120969772\n",
      "canvas step 2, L2Loss = 0.011750823818147182\n",
      "canvas step 3, L2Loss = 0.009670603089034557\n",
      "canvas step 4, L2Loss = 0.009401991963386536\n",
      "canvas step 5, L2Loss = 0.008408738300204277\n",
      "canvas step 6, L2Loss = 0.007953529246151447\n",
      "canvas step 7, L2Loss = 0.00739780068397522\n",
      "canvas step 8, L2Loss = 0.007234716322273016\n",
      "canvas step 9, L2Loss = 0.006828180979937315\n",
      "canvas step 10, L2Loss = 0.00659077987074852\n",
      "canvas step 11, L2Loss = 0.006394834723323584\n",
      "canvas step 12, L2Loss = 0.00618002749979496\n",
      "canvas step 13, L2Loss = 0.0060562752187252045\n",
      "canvas step 14, L2Loss = 0.005843774881213903\n",
      "canvas step 15, L2Loss = 0.005676768720149994\n",
      "canvas step 16, L2Loss = 0.005596315022557974\n",
      "canvas step 17, L2Loss = 0.005554175470024347\n",
      "canvas step 18, L2Loss = 0.005462374538183212\n",
      "canvas step 19, L2Loss = 0.005311783403158188\n",
      "canvas step 20, L2Loss = 0.005154225509613752\n",
      "canvas step 21, L2Loss = 0.005135057028383017\n",
      "canvas step 22, L2Loss = 0.005055594723671675\n",
      "canvas step 23, L2Loss = 0.004910438787192106\n",
      "canvas step 24, L2Loss = 0.004775910172611475\n",
      "canvas step 25, L2Loss = 0.004707332234829664\n",
      "canvas step 26, L2Loss = 0.004647776950150728\n",
      "canvas step 27, L2Loss = 0.004626198671758175\n",
      "canvas step 28, L2Loss = 0.004542336333543062\n",
      "canvas step 29, L2Loss = 0.004490136634558439\n",
      "canvas step 30, L2Loss = 0.004421337973326445\n",
      "canvas step 31, L2Loss = 0.004369249101728201\n",
      "canvas step 32, L2Loss = 0.004335571546107531\n",
      "canvas step 33, L2Loss = 0.004285548813641071\n",
      "canvas step 34, L2Loss = 0.004263682756572962\n",
      "canvas step 35, L2Loss = 0.004189459141343832\n",
      "canvas step 36, L2Loss = 0.004175730049610138\n",
      "canvas step 37, L2Loss = 0.004158225376158953\n",
      "canvas step 38, L2Loss = 0.004099490586668253\n",
      "canvas step 39, L2Loss = 0.004067560192197561\n",
      "divided canvas step 0, L2Loss = 0.0021989261731505394\n",
      "divided canvas step 1, L2Loss = 0.0016729563940316439\n",
      "divided canvas step 2, L2Loss = 0.0013433161657303572\n",
      "divided canvas step 3, L2Loss = 0.0011705688666552305\n",
      "divided canvas step 4, L2Loss = 0.0010458295000717044\n",
      "divided canvas step 5, L2Loss = 0.000960362667683512\n",
      "divided canvas step 6, L2Loss = 0.0008985137101262808\n",
      "divided canvas step 7, L2Loss = 0.0008488132734782994\n",
      "divided canvas step 8, L2Loss = 0.0008079590043053031\n",
      "divided canvas step 9, L2Loss = 0.0007640128605999053\n",
      "divided canvas step 10, L2Loss = 0.000734751345589757\n",
      "divided canvas step 11, L2Loss = 0.0007033341098576784\n",
      "divided canvas step 12, L2Loss = 0.0006729285232722759\n",
      "divided canvas step 13, L2Loss = 0.0006438718410208821\n",
      "divided canvas step 14, L2Loss = 0.0006190318381413817\n",
      "divided canvas step 15, L2Loss = 0.0005983226001262665\n",
      "divided canvas step 16, L2Loss = 0.0005822500097565353\n",
      "divided canvas step 17, L2Loss = 0.0005706782103516161\n",
      "divided canvas step 18, L2Loss = 0.0005606976337730885\n",
      "divided canvas step 19, L2Loss = 0.0005487283342517912\n",
      "divided canvas step 20, L2Loss = 0.0005403786199167371\n",
      "divided canvas step 21, L2Loss = 0.0005313162109814584\n",
      "divided canvas step 22, L2Loss = 0.0005218773731030524\n",
      "divided canvas step 23, L2Loss = 0.0005150098004378378\n",
      "divided canvas step 24, L2Loss = 0.0005080503178760409\n",
      "divided canvas step 25, L2Loss = 0.0005026941071264446\n",
      "divided canvas step 26, L2Loss = 0.000496919674333185\n",
      "divided canvas step 27, L2Loss = 0.0004913300508633256\n",
      "divided canvas step 28, L2Loss = 0.00048700172919780016\n",
      "divided canvas step 29, L2Loss = 0.0004823015769943595\n",
      "divided canvas step 30, L2Loss = 0.0004770389059558511\n",
      "divided canvas step 31, L2Loss = 0.00047168994206003845\n",
      "divided canvas step 32, L2Loss = 0.0004666690656449646\n",
      "divided canvas step 33, L2Loss = 0.000462247320683673\n",
      "divided canvas step 34, L2Loss = 0.0004574137565214187\n",
      "divided canvas step 35, L2Loss = 0.00045269657857716084\n",
      "divided canvas step 36, L2Loss = 0.00044848397374153137\n",
      "divided canvas step 37, L2Loss = 0.00044458836782723665\n",
      "divided canvas step 38, L2Loss = 0.0004403467464726418\n",
      "divided canvas step 39, L2Loss = 0.0004369223606772721\n"
     ]
    }
   ],
   "source": [
    "!python3 baseline_modelfree/test.py --max_step=80 --actor=actor.pkl --renderer=renderer.pkl --img=image/test.png --divide=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLM4U6F0_yjV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.0.1 Copyright (c) 2000-2022 the FFmpeg developers\r\n",
      "  built with Apple clang version 13.1.6 (clang-1316.0.21.2)\r\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/5.0.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-neon\r\n",
      "  libavutil      57. 17.100 / 57. 17.100\r\n",
      "  libavcodec     59. 18.100 / 59. 18.100\r\n",
      "  libavformat    59. 16.100 / 59. 16.100\r\n",
      "  libavdevice    59.  4.100 / 59.  4.100\r\n",
      "  libavfilter     8. 24.100 /  8. 24.100\r\n",
      "  libswscale      6.  4.100 /  6.  4.100\r\n",
      "  libswresample   4.  3.100 /  4.  3.100\r\n",
      "  libpostproc    56.  3.100 / 56.  3.100\r\n",
      "\u001b[0;33mTrailing option(s) found in the command: may be ignored.\r\n",
      "\u001b[0mInput #0, image2, from 'output/generated%d.png':\r\n",
      "  Duration: 00:00:13.33, start: 0.000000, bitrate: N/A\r\n",
      "  Stream #0:0: Video: png, rgb24(pc), 128x127, 30 fps, 30 tbr, 30 tbn\r\n",
      "File 'video.mp4' already exists. Overwrite? [y/N] "
     ]
    }
   ],
   "source": [
    "!ffmpeg -r 30 -f image2 -i output/generated%d.png -s 512x512 -c:v libx264 -pix_fmt yuv420p video.mp4 -q:v 0 -q:a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekY7HcBeh8zl"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import moviepy.editor as mpy\n",
    "display(mpy.ipython_display('video.mp4', height=256, max_duration=100.))\n",
    "display(Image('output/generated399.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mAkgRjwwuf"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-p0NhqyTqO_"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXAV9RwkTwKh"
   },
   "outputs": [],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzZUVjdrET2G"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/open?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgguAW3eETVd"
   },
   "outputs": [],
   "source": [
    "!unzip img_align_celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBH--DY-sK8V"
   },
   "outputs": [],
   "source": [
    "!rm img_align_celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6mVpjvBvzrb"
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-PYJVt8pc6BP"
   },
   "outputs": [],
   "source": [
    "!python3 baseline/train_renderer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZWjNmD23gKm"
   },
   "outputs": [],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehnzhWn9GG4I"
   },
   "outputs": [],
   "source": [
    "%%writefile baseline/env.py\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from DRL.ddpg import decode\n",
    "from utils.util import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "aug = transforms.Compose(\n",
    "            [transforms.ToPILImage(),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             ])\n",
    "\n",
    "width = 128\n",
    "convas_area = width * width\n",
    "\n",
    "img_train = []\n",
    "img_test = []\n",
    "train_num = 0\n",
    "test_num = 0\n",
    "\n",
    "class Paint:\n",
    "    def __init__(self, batch_size, max_step):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_step = max_step\n",
    "        self.action_space = (13)\n",
    "        self.observation_space = (self.batch_size, width, width, 7)\n",
    "        self.test = False\n",
    "        \n",
    "    def load_data(self):\n",
    "        # CelebA\n",
    "        global train_num, test_num\n",
    "        for i in range(200000):\n",
    "            img_id = '%06d' % (i + 1)\n",
    "            try:\n",
    "                img = cv2.imread('./data/img_align_celeba/' + img_id + '.jpg', cv2.IMREAD_UNCHANGED)\n",
    "                img = cv2.resize(img, (width, width))\n",
    "                if i > 2000:                \n",
    "                    train_num += 1\n",
    "                    img_train.append(img)\n",
    "                else:\n",
    "                    test_num += 1\n",
    "                    img_test.append(img)\n",
    "            finally:\n",
    "                if (i + 1) % 10000 == 0:                    \n",
    "                    print('loaded {} images'.format(i + 1))\n",
    "        print('finish loading data, {} training images, {} testing images'.format(str(train_num), str(test_num)))\n",
    "        \n",
    "    def pre_data(self, id, test):\n",
    "        if test:\n",
    "            img = img_test[id]\n",
    "        else:\n",
    "            img = img_train[id]\n",
    "        if not test:\n",
    "            img = aug(img)\n",
    "        img = np.asarray(img)\n",
    "        return np.transpose(img, (2, 0, 1))\n",
    "    \n",
    "    def reset(self, test=False, begin_num=False):\n",
    "        self.test = test\n",
    "        self.imgid = [0] * self.batch_size\n",
    "        self.gt = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
    "        for i in range(self.batch_size):\n",
    "            if test:\n",
    "                id = (i + begin_num)  % test_num\n",
    "            else:\n",
    "                id = np.random.randint(train_num)\n",
    "            self.imgid[i] = id\n",
    "            self.gt[i] = torch.tensor(self.pre_data(id, test))\n",
    "        self.tot_reward = ((self.gt.float() / 255) ** 2).mean(1).mean(1).mean(1)\n",
    "        self.stepnum = 0\n",
    "        self.canvas = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
    "        self.lastdis = self.ini_dis = self.cal_dis()\n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        # canvas B * 3 * width * width\n",
    "        # gt B * 3 * width * width\n",
    "        # T B * 1 * width * width\n",
    "        ob = []\n",
    "        T = torch.ones([self.batch_size, 1, width, width], dtype=torch.uint8) * self.stepnum\n",
    "        return torch.cat((self.canvas, self.gt, T.to(device)), 1) # canvas, img, T\n",
    "\n",
    "    def cal_trans(self, s, t):\n",
    "        return (s.transpose(0, 3) * t).transpose(0, 3)\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.canvas = (decode(action, self.canvas.float() / 255) * 255).byte()\n",
    "        self.stepnum += 1\n",
    "        ob = self.observation()\n",
    "        done = (self.stepnum == self.max_step)\n",
    "        reward = self.cal_reward() # np.array([0.] * self.batch_size)\n",
    "        return ob.detach(), reward, np.array([done] * self.batch_size), None\n",
    "\n",
    "    def cal_dis(self):\n",
    "        return (((self.canvas.float() - self.gt.float()) / 255) ** 2).mean(1).mean(1).mean(1)\n",
    "    \n",
    "    def cal_reward(self):\n",
    "        dis = self.cal_dis()\n",
    "        reward = (self.lastdis - dis) / (self.ini_dis + 1e-8)\n",
    "        self.lastdis = dis\n",
    "        return to_numpy(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kwVmo6yv1w3"
   },
   "outputs": [],
   "source": [
    "!python3 baseline/train.py --max_step=200 --debug --batch_size=96"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "learningtopaint.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
